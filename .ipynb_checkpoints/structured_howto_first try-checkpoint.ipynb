{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# improts for our used libs\n",
    "import utils\n",
    "import torch\n",
    "import analyse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import model_simple as ms\n",
    "\n",
    "from torch import nn\n",
    "from data_loader import get_loader\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X for model and y for decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'PAH3DEEUR_1 Min_Bid_2008.10.21_2018.10.27.csv'\n",
    "# filename = 'BAYNDEEUR_1 Min_Bid_2015.03.20_2018.10.27.csv'\n",
    "filename = 'BMWDEEUR_1 Min_Bid_2015.03.24_2018.10.27.csv'\n",
    "\n",
    "timeframe = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_X_y(filename, loss_ratio=6, timeframe=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to create our csv files for X and for y (X = the input for our xgboost and y the output of our xgboost)\n",
    "# remeber X will be also used for our Autoencoders\n",
    "X = pd.read_csv('data/X_' + filename)\n",
    "y = pd.read_csv('data/y_' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just for evaulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if same length in the table\n",
    "print(X.shape[0] == y.shape[0])\n",
    "# show me which values we got :-)\n",
    "unique, counts = np.unique(y['2'], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeframe is meant the shape of tensor regarding fields\n",
    "# so can be diffrent from timeframe abofe\n",
    "ts = 60*24\n",
    "data = get_loader(data_path='data/X_' + filename, timeframe=ts, batch_size=51280)\n",
    "# set learning rate and input dim\n",
    "lr = 1e-1\n",
    "ds = iter(data)\n",
    "input_dim = ds.next().shape[2]\n",
    "# inizialise model\n",
    "model = ms.SimpleAutoencoder(input_dim=input_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# model # to print my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "epoch_num = 1\n",
    "model.cuda()\n",
    "model.train()\n",
    "criterion.cuda()\n",
    "for epoch in range(epoch_num):\n",
    "    for i, x in enumerate(data):\n",
    "        # forward\n",
    "        x = x.float().cuda()\n",
    "        y = model(x).float().cuda()\n",
    "        loss = criterion(y, x)\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ------- log output ---------\n",
    "    print('epoch [{}/{}], loss:{:.6f}, MSE_loss:{:.6f}'\n",
    "          .format(epoch + 1, epoch_num, loss.data, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate and save model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = get_loader(data_path='data/X_' + filename, timeframe=ts, batch_size=1)\n",
    "# prefill results until first dataloader element\n",
    "result = [0] * ts\n",
    "criterion.cuda()\n",
    "for i, x in enumerate(dp):\n",
    "    # add value to pandas \n",
    "    pred = model(x.float().cuda())\n",
    "    result.append(criterion(x.float().cuda(), pred).data.item())\n",
    "    if(i % 10000 == 0):\n",
    "        print('still running ' + str(i))\n",
    "pd.DataFrame(result).to_csv('data/ym__' + filename, header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "xgEvaluation() got multiple values for argument 'i_end'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9b5b45c51588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mana\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAnalyse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mana\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxgEvaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_confusionm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: xgEvaluation() got multiple values for argument 'i_end'"
     ]
    }
   ],
   "source": [
    "filename_X = \"data/ym__\" + filename\n",
    "filename_y = 'data/y_' + filename\n",
    "# X = pd.read_csv(filename_X, header=None)\n",
    "# y = pd.read_csv(filename_y)\n",
    "\n",
    "\n",
    "# utils.xgEvaluation(X, y, y_field='5', i_end=50, debug_i=5, threshold_confusionm=0.3)\n",
    "\n",
    "ana = analyse.Analyse(filename_X, filename_y, filename)\n",
    "ana.xgEvaluation(i_end=50, debug_i=5, threshold_confusionm=0.3, y_field='5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
