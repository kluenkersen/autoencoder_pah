{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# improts for our used libs\n",
    "import utils\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import model_simple as ms\n",
    "\n",
    "from torch import nn\n",
    "from data_loader import get_loader\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X for model and y for decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeframe = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_X_y('PAH3DEEUR_1 Min_Bid_2008.10.21_2018.10.27.csv', loss_ratio=3, timeframe=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to create our csv files for X and for y (X = the input for our xgboost and y the output of our xgboost)\n",
    "# remeber X will be also used for our Autoencoders\n",
    "X = pd.read_csv('data/X_PAH3DEEUR_1 Min_Bid_2008.10.21_2018.10.27.csv')\n",
    "y = pd.read_csv('data/y_PAH3DEEUR_1 Min_Bid_2008.10.21_2018.10.27.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just for evaulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if same length in the table\n",
    "print(X.shape[0] == y.shape[0])\n",
    "# show me which values we got :-)\n",
    "unique, counts = np.unique(y['2'], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeframe is meant the shape of tensor regarding fields\n",
    "# so can be diffrent from timeframe abofe\n",
    "ts = 60*24\n",
    "data = get_loader(data_path='data/X_PAH3DEEUR_1 Min_Bid_2008.10.21_2018.10.27.csv', timeframe=ts, batch_size=51280)\n",
    "# set learning rate and input dim\n",
    "lr = 1e-1\n",
    "ds = iter(data)\n",
    "input_dim = ds.next().shape[2]\n",
    "# inizialise model\n",
    "model = ms.SimpleAutoencoder(input_dim=input_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# model # to print my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "epoch_num = 1\n",
    "model.cuda()\n",
    "model.train()\n",
    "criterion.cuda()\n",
    "for epoch in range(epoch_num):\n",
    "    for i, x in enumerate(data):\n",
    "        # forward\n",
    "        x = x.float().cuda()\n",
    "        y = model(x).float().cuda()\n",
    "        loss = criterion(y, x)\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ------- log output ---------\n",
    "    print('epoch [{}/{}], loss:{:.6f}, MSE_loss:{:.6f}'\n",
    "          .format(epoch + 1, epoch_num, loss.data, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate and save model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = get_loader(data_path='data/X_PAH3DEEUR_1 Min_Bid_2008.10.21_2018.10.27.csv', timeframe=ts, batch_size=1)\n",
    "# prefill results until first dataloader element\n",
    "result = [0] * ts\n",
    "criterion.cuda()\n",
    "for i, x in enumerate(dp):\n",
    "    # add value to pandas \n",
    "    pred = model(x.float().cuda())\n",
    "    result.append(criterion(x.float().cuda(), pred).data.item())\n",
    "    if(i % 10000 == 0):\n",
    "        print('still running' + i)\n",
    "pd.DataFrame(result).to_csv('data/ym__PAH3DEEUR_1 Min_Bid_2008.10.21_2018.10.27.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result).to_csv('data/ym___PAH3DEEUR_1 Min_Bid_2008.10.21_2018.10.27.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treshhold: 0.5 i: 0\n",
      "[[389898      0]\n",
      " [  6920      0]]\n",
      "treshhold: 0.5 i: 5\n",
      "[[389898      0]\n",
      " [  6920      0]]\n",
      "treshhold: 0.5 i: 10\n",
      "[[389898      0]\n",
      " [  6920      0]]\n",
      "treshhold: 0.5 i: 15\n",
      "[[389898      0]\n",
      " [  6920      0]]\n",
      "treshhold: 0.5 i: 20\n",
      "[[389898      0]\n",
      " [  6916      4]]\n",
      "treshhold: 0.5 i: 25\n",
      "[[389896      2]\n",
      " [  6919      1]]\n",
      "treshhold: 0.5 i: 30\n",
      "[[389890      8]\n",
      " [  6909     11]]\n",
      "treshhold: 0.5 i: 35\n",
      "[[389897      1]\n",
      " [  6913      7]]\n",
      "treshhold: 0.5 i: 40\n",
      "[[389895      3]\n",
      " [  6909     11]]\n",
      "treshhold: 0.5 i: 45\n",
      "[[389892      6]\n",
      " [  6907     13]]\n",
      "treshhold: 0.5 i: 49\n",
      "[[389887     11]\n",
      " [  6907     13]]\n"
     ]
    }
   ],
   "source": [
    "filename_X = \"data/ym___PAH3DEEUR_1 Min_Bid_2008.10.21_2018.10.27.csv\"\n",
    "filename_y = 'data/y_PAH3DEEUR_1 Min_Bid_2008.10.21_2018.10.27.csv'\n",
    "X = pd.read_csv(filename_X, header=None)\n",
    "y = pd.read_csv(filename_y)\n",
    "\n",
    "utils.xgEvaluation(X, y, y_field='4', i_end=50, debug_i=5, threshold_confusionm=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
